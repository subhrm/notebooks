{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPt483tnrLOziqQLpfFwTBK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["%pip install -U datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"kDuiDDGQH6nP","executionInfo":{"status":"ok","timestamp":1752298426194,"user_tz":-330,"elapsed":9886,"user":{"displayName":"Subhendu Mishra","userId":"07522839602294169270"}},"outputId":"2d5240b6-fe40-4e98-8445-11b8091be4e0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n","Collecting datasets\n","  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n","Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.7.9)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: fsspec, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.2\n","    Uninstalling fsspec-2025.3.2:\n","      Successfully uninstalled fsspec-2025.3.2\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 2.14.4\n","    Uninstalling datasets-2.14.4:\n","      Successfully uninstalled datasets-2.14.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-4.0.0 fsspec-2025.3.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["datasets","fsspec"]},"id":"b23b9acd5fa84cff8e6af9a60ec8e23f"}},"metadata":{}}]},{"cell_type":"code","execution_count":15,"metadata":{"id":"rrkl2UBnC5a8","executionInfo":{"status":"ok","timestamp":1752301797544,"user_tz":-330,"elapsed":4,"user":{"displayName":"Subhendu Mishra","userId":"07522839602294169270"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from datasets import load_dataset\n","import numpy as np\n","import os\n","from tqdm import tqdm\n","import math\n","import re\n","from collections import Counter\n","from textwrap import wrap\n","import plotly.express as px\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["## Load and Explore SQuAD Dataset\n","> To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","> Variable Name `HF_TOKEN`"],"metadata":{"id":"NVixsByAE-VE"}},{"cell_type":"code","source":["# --- 1. Load Stanford SQuAD Dataset ---\n","print(\"Loading SQuAD dataset...\")\n","# Load the SQuAD v1.1 dataset from the Hugging Face datasets library\n","# This will download the dataset if it's not already cached.\n","# Specify a revision ('1.1' or '2.0') to potentially avoid glob pattern issues\n","squad_dataset = load_dataset(\"rajpurkar/squad_v2\")\n","print(\"SQuAD dataset loaded successfully.\")\n","\n","# --- 2. Explore SQuAD Dataset ---\n","print(\"\\n--- SQuAD Dataset Structure and Examples ---\")\n","print(f\"Dataset splits: {squad_dataset.keys()}\")\n","print(f\"Number of training examples: {len(squad_dataset['train'])}\")\n","print(f\"Number of validation examples: {len(squad_dataset['validation'])}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kSkitnYJEyqT","executionInfo":{"status":"ok","timestamp":1752301674437,"user_tz":-330,"elapsed":1254,"user":{"displayName":"Subhendu Mishra","userId":"07522839602294169270"}},"outputId":"07abc238-9ade-4756-f9b7-f80020787ceb"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading SQuAD dataset...\n","SQuAD dataset loaded successfully.\n","\n","--- SQuAD Dataset Structure and Examples ---\n","Dataset splits: dict_keys(['train', 'validation'])\n","Number of training examples: 130319\n","Number of validation examples: 11873\n"]}]},{"cell_type":"code","source":["squad_dataset['train'][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jnvibUsBUbrC","executionInfo":{"status":"ok","timestamp":1752301693447,"user_tz":-330,"elapsed":7,"user":{"displayName":"Subhendu Mishra","userId":"07522839602294169270"}},"outputId":"5e88b16a-e10a-4b23-ca0a-5ff49cdbd0cc"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': '56be85543aeaaa14008c9063',\n"," 'title': 'Beyoncé',\n"," 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n"," 'question': 'When did Beyonce start becoming popular?',\n"," 'answers': {'text': ['in the late 1990s'], 'answer_start': [269]}}"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["def print_squad_data(example, width=120):\n","    context = \"\\n\\t\".join(wrap(example['context'],width))\n","    question = example['question']\n","    answers = example['answers']\n","    print(f\"  Context: \\n\\t{context}\")\n","    print(f\"  Question: {question}\")\n","    print(f\"  Answer Text: {answers['text'][0]}\")\n","    answer_start = answers['answer_start'][0]\n","    answer_length = len(answers['text'][0])\n","    print(f\"  Answer Start: {answer_start}\")\n","    print(f\"  Answer block: {example['context'][answer_start : answer_start + answer_length]}\")\n","\n","# Print a few examples from the training set\n","print(\"\\nExample from training set:\")\n","\n","# Display a few examples from the training set\n","print(\"\\nExample from training set:\")\n","example = squad_dataset['train'][0]\n","print_squad_data(example)\n","\n","# Print a few examples from the validation set\n","print(\"\\nExample from validation set:\")\n","example = squad_dataset['validation'][0]\n","print_squad_data(example)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PD9Pa9aaUW8l","executionInfo":{"status":"ok","timestamp":1752302328476,"user_tz":-330,"elapsed":8,"user":{"displayName":"Subhendu Mishra","userId":"07522839602294169270"}},"outputId":"7dde80a4-10a1-4eea-9c6a-fabeefb55958"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Example from training set:\n","\n","Example from training set:\n","  Context: \n","\tBeyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter,\n","\trecord producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing\n","\tcompetitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by\n","\ther father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw\n","\tthe release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide,\n","\tearned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n","  Question: When did Beyonce start becoming popular?\n","  Answer Text: in the late 1990s\n","  Answer Start: 269\n","  Answer block: in the late 1990s\n","\n","Example from validation set:\n","  Context: \n","\tThe Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries\n","\tgave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders\n","\tand pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III\n","\tof West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations,\n","\ttheir descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and\n","\tethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over\n","\tthe succeeding centuries.\n","  Question: In what country is Normandy located?\n","  Answer Text: France\n","  Answer Start: 159\n","  Answer block: France\n"]}]},{"cell_type":"code","source":["train_context_lengths = [ len(ex['context']) for ex in squad_dataset['train']]\n","val_context_lengths = [ len(ex['context']) for ex in squad_dataset['validation']]\n","train_num_of_answers = [ len(ex['answers']['text']) for ex in squad_dataset['train']]\n","val_num_of_answers = [ len(ex['answers']['text']) for ex in squad_dataset['validation']]\n","\n","print(f\"Average context length in training set: {np.mean(train_context_lengths)}\")\n","print(f\"Average context length in validation set: {np.mean(val_context_lengths)}\")\n","print(f\"Max context length in training set: {np.max(train_context_lengths)}\")\n","print(f\"Max context length in validation set: {np.max(val_context_lengths)}\")\n","print(f\"Min context length in training set: {np.min(train_context_lengths)}\")\n","print(f\"Min context length in validation set: {np.min(val_context_lengths)}\")\n","\n","print(f\"Count of answers per Q in training set: {Counter(train_num_of_answers)}\")\n","print(f\"Count of answers per Q in validation set: {Counter(val_num_of_answers)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LZBPcIPCItTi","executionInfo":{"status":"ok","timestamp":1752305192444,"user_tz":-330,"elapsed":24597,"user":{"displayName":"Subhendu Mishra","userId":"07522839602294169270"}},"outputId":"610f470e-f4cf-493b-cbef-fcf0c29d5461"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Average context length in training set: 754.5662873410631\n","Average context length in validation set: 810.9731323170219\n","Max context length in training set: 3706\n","Max context length in validation set: 4063\n","Min context length in training set: 151\n","Min context length in validation set: 169\n","Count of answers per Q in training set: Counter({1: 86821, 0: 43498})\n","Count of answers per Q in validation set: Counter({0: 5945, 3: 4238, 5: 945, 4: 625, 2: 88, 6: 31, 1: 1})\n"]}]},{"cell_type":"code","source":["# pLot the context lengths\n","_=plt.hist(train_context_lengths, bins=500, alpha=0.8, label='Training')\n","_=plt.hist(val_context_lengths, bins=300, alpha=0.8, label='Validation')\n","plt.legend()\n","plt.xlabel('Context Length')\n","plt.ylabel('Frequency')\n","plt.title('Distribution of Context Lengths')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"a6oAoCPXKryK","executionInfo":{"status":"ok","timestamp":1752299190250,"user_tz":-330,"elapsed":2436,"user":{"displayName":"Subhendu Mishra","userId":"07522839602294169270"}},"outputId":"e527f393-809a-4a69-af6b-d0bf76323d11"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"pEV5IvG0ItKO","executionInfo":{"status":"aborted","timestamp":1752299120762,"user_tz":-330,"elapsed":11258,"user":{"displayName":"Subhendu Mishra","userId":"07522839602294169270"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DHLgU-WHItBX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## --- Configuration ---"],"metadata":{"id":"w9PSb-cSIpSa"}},{"cell_type":"code","source":["\n","# Set device for training (GPU if available, else CPU)\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {DEVICE}\")\n","\n","# GloVe embedding configuration\n","GLOVE_PATH = 'glove.6B/glove.6B.50d.txt' # Path to your GloVe file (e.g., glove.6B.50d.txt)\n","EMBEDDING_DIM = 50 # Dimension of GloVe embeddings (must match the chosen GloVe file)\n","\n","# Model hyper-parameters\n","MAX_CONTEXT_LEN = 300 # Maximum number of tokens for context\n","MAX_QUESTION_LEN = 50 # Maximum number of tokens for question\n","HIDDEN_DIM = EMBEDDING_DIM # Hidden dimension for the transformer block\n","NUM_HEADS = 1 # Number of attention heads (as requested, only one)\n","FF_DIM = EMBEDDING_DIM * 4 # Dimension for the feed-forward network\n","DROPOUT_RATE = 0.1\n","\n","# Training hyper-parameters\n","BATCH_SIZE = 16\n","NUM_EPOCHS = 5\n","LEARNING_RATE = 1e-4"],"metadata":{"id":"6SCEDKTwEvXc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# --- 3. Load GloVe Vectors ---\n","print(f\"\\nLoading GloVe embeddings from {GLOVE_PATH}...\")\n","word_to_idx = {} # Dictionary to map words to their indices\n","idx_to_word = [] # List to map indices back to words\n","embeddings = [] # List to store embedding vectors\n","\n","# Add a special token for padding and unknown words\n","PAD_TOKEN = '<pad>'\n","UNK_TOKEN = '<unk>'\n","word_to_idx[PAD_TOKEN] = 0\n","idx_to_word.append(PAD_TOKEN)\n","embeddings.append(np.zeros(EMBEDDING_DIM)) # Padding token has a zero vector\n","\n","word_to_idx[UNK_TOKEN] = 1\n","idx_to_word.append(UNK_TOKEN)\n","# Initialize UNK token with a random vector or average vector (here, random)\n","embeddings.append(np.random.rand(EMBEDDING_DIM) * 0.01)\n","\n","# Read the GloVe file\n","try:\n","    with open(GLOVE_PATH, 'r', encoding='utf-8') as f:\n","        for line in tqdm(f, desc=\"Reading GloVe\"):\n","            values = line.split()\n","            word = values[0]\n","            vector = np.asarray(values[1:], dtype='float32')\n","            if len(vector) == EMBEDDING_DIM: # Ensure vector dimension matches\n","                word_to_idx[word] = len(word_to_idx)\n","                idx_to_word.append(word)\n","                embeddings.append(vector)\n","    # Convert the list of embeddings to a numpy array\n","    embeddings_matrix = np.array(embeddings, dtype='float32')\n","    # Convert to a PyTorch tensor\n","    pretrained_embeddings = torch.from_numpy(embeddings_matrix).to(DEVICE)\n","    print(f\"Loaded {len(word_to_idx)} GloVe embeddings of dimension {EMBEDDING_DIM}.\")\n","except FileNotFoundError:\n","    print(f\"Error: GloVe file not found at {GLOVE_PATH}. Please download it and place it correctly.\")\n","    print(\"You can download GloVe from: https://nlp.stanford.edu/projects/glove/\")\n","    print(\"For example, download 'glove.6B.zip', extract it, and place 'glove.6B.50d.txt' in the same directory as this script, or update GLOVE_PATH.\")\n","    exit() # Exit if GloVe file is not found\n","\n","# --- Helper function for tokenization and indexing ---\n","# Simple word tokenizer (can be replaced with NLTK or spaCy for better tokenization)\n","def simple_tokenize(text):\n","    # Convert to lowercase, remove punctuation except apostrophes, split by space\n","    text = text.lower()\n","    text = re.sub(r\"[^a-z0-9']+\", \" \", text) # Keep letters, numbers, apostrophes\n","    tokens = text.split()\n","    return tokens\n","\n","# Function to convert tokens to indices\n","def tokens_to_indices(tokens, word_to_idx, max_len, unk_idx=1, pad_idx=0):\n","    indices = [word_to_idx.get(token, unk_idx) for token in tokens]\n","    # Pad or truncate\n","    if len(indices) < max_len:\n","        indices.extend([pad_idx] * (max_len - len(indices)))\n","    else:\n","        indices = indices[:max_len]\n","    return indices\n","\n","# Function to find answer start and end token indices\n","def find_answer_token_indices(context_tokens, answer_text, answer_start_char, context_original):\n","    # This is a simplified approach and might not be perfect for all cases\n","    # A more robust approach would involve character-level mapping or spaCy's tokenization\n","\n","    # Reconstruct context from tokens to find character offsets\n","    # This is crucial because simple_tokenize changes character offsets\n","    current_char_offset = 0\n","    token_char_map = [] # List of (start_char, end_char) for each token\n","    for token in context_tokens:\n","        # Find the token in the original context (case-insensitive)\n","        # This is a heuristic and might fail if tokens are not unique or context is complex\n","        match = re.search(re.escape(token), context_original[current_char_offset:], re.IGNORECASE)\n","        if match:\n","            token_start_char = current_char_offset + match.start()\n","            token_end_char = current_char_offset + match.end()\n","            token_char_map.append((token_start_char, token_end_char))\n","            current_char_offset = token_end_char # Move cursor past this token\n","        else:\n","            # If token not found, assume it's a special character or complex case\n","            # For simplicity, we'll just advance the offset by token length + 1 (for space)\n","            # A more robust solution would re-align with original text\n","            token_char_map.append((current_char_offset, current_char_offset + len(token)))\n","            current_char_offset += len(token) + 1 # +1 for potential space\n","\n","    # Find the start and end token indices\n","    start_token_idx = -1\n","    end_token_idx = -1 # Inclusive end index\n","\n","    for i, (token_start_char, token_end_char) in enumerate(token_char_map):\n","        # Check if the answer starts within or at the beginning of this token\n","        if answer_start_char >= token_start_char and answer_start_char < token_end_char:\n","            start_token_idx = i\n","            break\n","\n","    # If start token found, find the end token\n","    if start_token_idx != -1:\n","        # Calculate the end character of the answer in the original context\n","        answer_end_char = answer_start_char + len(answer_text)\n","\n","        for i in range(start_token_idx, len(token_char_map)):\n","            token_start_char, token_end_char = token_char_map[i]\n","            # If the answer ends within or at the end of this token\n","            if answer_end_char <= token_end_char:\n","                end_token_idx = i\n","                break\n","            # If the answer extends beyond this token, continue searching\n","            elif answer_end_char > token_end_char and i == len(token_char_map) - 1:\n","                # If it's the last token and answer still extends, set end to last token\n","                end_token_idx = i\n","                break\n","\n","    # If answer not found or indices are invalid, set to 0 (padding token)\n","    if start_token_idx == -1 or end_token_idx == -1:\n","        start_token_idx = 0\n","        end_token_idx = 0\n","\n","    # Ensure indices are within MAX_CONTEXT_LEN\n","    start_token_idx = min(start_token_idx, MAX_CONTEXT_LEN - 1)\n","    end_token_idx = min(end_token_idx, MAX_CONTEXT_LEN - 1)\n","\n","    # Ensure start_token_idx <= end_token_idx\n","    if start_token_idx > end_token_idx:\n","        start_token_idx = end_token_idx\n","\n","    return start_token_idx, end_token_idx\n","\n","\n","# --- Custom SQuAD Dataset Class ---\n","class SQuADDataset(Dataset):\n","    def __init__(self, dataset_split, word_to_idx, max_context_len, max_question_len):\n","        self.dataset = dataset_split\n","        self.word_to_idx = word_to_idx\n","        self.max_context_len = max_context_len\n","        self.max_question_len = max_question_len\n","        self.unk_idx = word_to_idx[UNK_TOKEN]\n","        self.pad_idx = word_to_idx[PAD_TOKEN]\n","\n","        self.processed_data = []\n","        print(f\"Processing {len(self.dataset)} examples...\")\n","        for example in tqdm(self.dataset, desc=\"Preprocessing SQuAD\"):\n","            context = example['context']\n","            question = example['question']\n","            answer_text = example['answers']['text'][0]\n","            answer_start_char = example['answers']['answer_start'][0]\n","\n","            # Tokenize context and question\n","            context_tokens = simple_tokenize(context)\n","            question_tokens = simple_tokenize(question)\n","\n","            # Convert tokens to indices and pad/truncate\n","            context_indices = tokens_to_indices(context_tokens, self.word_to_idx, self.max_context_len, self.unk_idx, self.pad_idx)\n","            question_indices = tokens_to_indices(question_tokens, self.word_to_idx, self.max_question_len, self.unk_idx, self.pad_idx)\n","\n","            # Find answer token indices\n","            start_token_idx, end_token_idx = find_answer_token_indices(context_tokens, answer_text, answer_start_char, context)\n","\n","            self.processed_data.append({\n","                'context_indices': torch.tensor(context_indices, dtype=torch.long),\n","                'question_indices': torch.tensor(question_indices, dtype=torch.long),\n","                'start_token_idx': torch.tensor(start_token_idx, dtype=torch.long),\n","                'end_token_idx': torch.tensor(end_token_idx, dtype=torch.long)\n","            })\n","\n","    def __len__(self):\n","        return len(self.processed_data)\n","\n","    def __getitem__(self, idx):\n","        return self.processed_data[idx]\n","\n","# Create dataset instances\n","train_dataset = SQuADDataset(squad_dataset['train'], word_to_idx, MAX_CONTEXT_LEN, MAX_QUESTION_LEN)\n","val_dataset = SQuADDataset(squad_dataset['validation'], word_to_idx, MAX_CONTEXT_LEN, MAX_QUESTION_LEN)\n","\n","# Create DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","print(f\"Train loader has {len(train_loader)} batches.\")\n","print(f\"Validation loader has {len(val_loader)} batches.\")\n","\n","\n","# --- 4. Create Extractive QA Model ---\n","\n","# Sinusoidal Positional Encoding\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1) # Shape: (max_len, 1, d_model)\n","        self.register_buffer('pe', pe) # Register as buffer so it's not a model parameter\n","\n","    def forward(self, x):\n","        # x shape: (seq_len, batch_size, d_model)\n","        # Add positional encoding to the input\n","        return x + self.pe[:x.size(0), :]\n","\n","\n","# Single Self-Attention Head\n","class SelfAttentionHead(nn.Module):\n","    def __init__(self, embed_dim, head_dim):\n","        super(SelfAttentionHead, self).__init__()\n","        # Linear transformations for Query, Key, Value\n","        self.query_proj = nn.Linear(embed_dim, head_dim)\n","        self.key_proj = nn.Linear(embed_dim, head_dim)\n","        self.value_proj = nn.Linear(embed_dim, head_dim)\n","        self.scale = head_dim ** -0.5 # Scaling factor for dot product attention\n","\n","    def forward(self, query, key, value, mask=None):\n","        # Project inputs to query, key, value space\n","        Q = self.query_proj(query)\n","        K = self.key_proj(key)\n","        V = self.value_proj(value)\n","\n","        # Calculate attention scores (Q * K^T)\n","        # Q: (batch_size, seq_len, head_dim)\n","        # K.transpose(-2, -1): (batch_size, head_dim, seq_len)\n","        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale\n","\n","        # Apply mask if provided (for padding tokens)\n","        if mask is not None:\n","            attention_scores = attention_scores.masked_fill(mask == 0, float('-inf'))\n","\n","        # Apply softmax to get attention probabilities\n","        attention_probs = torch.softmax(attention_scores, dim=-1)\n","\n","        # Multiply attention probabilities with Value to get weighted sum\n","        # attention_probs: (batch_size, seq_len, seq_len)\n","        # V: (batch_size, seq_len, head_dim)\n","        output = torch.matmul(attention_probs, V) # (batch_size, seq_len, head_dim)\n","        return output\n","\n","\n","# Simple Transformer Block\n","class TransformerBlock(nn.Module):\n","    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.1):\n","        super(TransformerBlock, self).__init__()\n","        # For simplicity, we're using a single SelfAttentionHead directly\n","        # In a full MultiHeadAttention, we'd have multiple heads and then concatenate\n","        # Here, num_heads is fixed to 1, so head_dim == embed_dim\n","        assert num_heads == 1, \"This TransformerBlock is designed for a single attention head.\"\n","        self.attention_head = SelfAttentionHead(embed_dim, embed_dim) # head_dim = embed_dim for single head\n","\n","        # Layer Normalization\n","        self.norm1 = nn.LayerNorm(embed_dim)\n","        self.norm2 = nn.LayerNorm(embed_dim)\n","\n","        # Feed-forward network\n","        self.feed_forward = nn.Sequential(\n","            nn.Linear(embed_dim, ff_dim),\n","            nn.ReLU(),\n","            nn.Linear(ff_dim, embed_dim)\n","        )\n","\n","        # Dropout layers\n","        self.dropout1 = nn.Dropout(dropout_rate)\n","        self.dropout2 = nn.Dropout(dropout_rate)\n","\n","    def forward(self, x, mask=None):\n","        # x shape: (batch_size, seq_len, embed_dim)\n","\n","        # Self-attention part\n","        # Apply attention, then dropout, then add residual connection, then layer norm\n","        attn_output = self.attention_head(x, x, x, mask)\n","        x = self.norm1(x + self.dropout1(attn_output))\n","\n","        # Feed-forward part\n","        # Apply feed-forward, then dropout, then add residual connection, then layer norm\n","        ff_output = self.feed_forward(x)\n","        x = self.norm2(x + self.dropout2(ff_output))\n","        return x\n","\n","\n","# Extractive QA Model\n","class ExtractiveQAModel(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_heads, ff_dim, dropout_rate, pretrained_embeddings=None):\n","        super(ExtractiveQAModel, self).__init__()\n","        # Embedding layer\n","        if pretrained_embeddings is not None:\n","            self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=True, padding_idx=0)\n","        else:\n","            self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","\n","        # Positional Encoding\n","        self.pos_encoder = PositionalEncoding(embedding_dim)\n","\n","        # Transformer Block (single block as requested)\n","        self.transformer_block = TransformerBlock(hidden_dim, num_heads, ff_dim, dropout_rate)\n","\n","        # Output layers for predicting start and end token probabilities\n","        # These layers will take the transformer output for the context and project it\n","        # to a single logit for each token, representing its likelihood as start/end\n","        self.start_head = nn.Linear(hidden_dim, 1)\n","        self.end_head = nn.Linear(hidden_dim, 1)\n","\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","    def forward(self, context_indices, question_indices):\n","        # context_indices shape: (batch_size, max_context_len)\n","        # question_indices shape: (batch_size, max_question_len)\n","\n","        # Get embeddings for context and question\n","        context_embed = self.embedding(context_indices) # (batch_size, max_context_len, embedding_dim)\n","        question_embed = self.embedding(question_indices) # (batch_size, max_question_len, embedding_dim)\n","\n","        # Apply positional encoding\n","        # Transpose for PositionalEncoding: (seq_len, batch_size, embed_dim)\n","        context_embed_pe = self.pos_encoder(context_embed.transpose(0, 1)).transpose(0, 1)\n","        question_embed_pe = self.pos_encoder(question_embed.transpose(0, 1)).transpose(0, 1)\n","\n","        # Dropout after positional encoding\n","        context_embed_pe = self.dropout(context_embed_pe)\n","        question_embed_pe = self.dropout(question_embed_pe)\n","\n","        # Concatenate context and question embeddings\n","        # A common approach in QA models is to process context and question together\n","        # For simplicity, we'll process context independently and use question for attention\n","        # A more advanced model would use cross-attention between context and question.\n","        # Here, we'll just use context for the transformer block and assume the question\n","        # has implicitly influenced the context representation through shared embeddings\n","        # or a more complex interaction layer (which this simple model lacks).\n","        # For a truly simple single-block model, we'll just run the transformer on the context.\n","        # The question's role is primarily to guide the loss function during training.\n","\n","        # Create attention mask for context padding\n","        # mask shape: (batch_size, 1, 1, max_context_len) for broadcasting\n","        context_mask = (context_indices != 0).unsqueeze(1).unsqueeze(1) # 0 is PAD_TOKEN index\n","\n","        # Pass context embeddings through the transformer block\n","        transformer_output = self.transformer_block(context_embed_pe, mask=context_mask)\n","        # transformer_output shape: (batch_size, max_context_len, hidden_dim)\n","\n","        # Predict start and end logits\n","        start_logits = self.start_head(transformer_output).squeeze(-1) # (batch_size, max_context_len)\n","        end_logits = self.end_head(transformer_output).squeeze(-1)   # (batch_size, max_context_len)\n","\n","        # Apply mask to logits to prevent predicting padding tokens\n","        # Set logits of padding tokens to a very small number so they get 0 probability after softmax\n","        start_logits = start_logits.masked_fill(context_indices == 0, float('-inf'))\n","        end_logits = end_logits.masked_fill(context_indices == 0, float('-inf'))\n","\n","        return start_logits, end_logits\n","\n","\n","# Initialize the model\n","model = ExtractiveQAModel(\n","    vocab_size=len(word_to_idx),\n","    embedding_dim=EMBEDDING_DIM,\n","    hidden_dim=HIDDEN_DIM,\n","    num_heads=NUM_HEADS,\n","    ff_dim=FF_DIM,\n","    dropout_rate=DROPOUT_RATE,\n","    pretrained_embeddings=pretrained_embeddings\n",").to(DEVICE)\n","\n","print(\"\\n--- Model Architecture ---\")\n","print(model)\n","\n","# --- 5. Train and Evaluate the Model ---\n","\n","# Loss function: CrossEntropyLoss for start and end predictions\n","# We treat this as a classification problem where each token in the context\n","# has a probability of being the start/end of the answer.\n","criterion = nn.CrossEntropyLoss()\n","\n","# Optimizer: Adam\n","optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","print(\"\\n--- Starting Training ---\")\n","for epoch in range(NUM_EPOCHS):\n","    model.train() # Set model to training mode\n","    total_train_loss = 0\n","\n","    for batch_idx, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\")):\n","        context_indices = batch['context_indices'].to(DEVICE)\n","        question_indices = batch['question_indices'].to(DEVICE)\n","        start_labels = batch['start_token_idx'].to(DEVICE)\n","        end_labels = batch['end_token_idx'].to(DEVICE)\n","\n","        optimizer.zero_grad() # Clear gradients\n","\n","        # Forward pass\n","        start_logits, end_logits = model(context_indices, question_indices)\n","\n","        # Calculate loss for start and end predictions\n","        start_loss = criterion(start_logits, start_labels)\n","        end_loss = criterion(end_logits, end_labels)\n","        loss = start_loss + end_loss # Total loss is sum of start and end losses\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_train_loss += loss.item()\n","\n","    avg_train_loss = total_train_loss / len(train_loader)\n","    print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f}\")\n","\n","    # --- Evaluation ---\n","    model.eval() # Set model to evaluation mode\n","    total_val_loss = 0\n","    correct_start_predictions = 0\n","    correct_end_predictions = 0\n","    total_predictions = 0\n","\n","    with torch.no_grad(): # Disable gradient calculation for evaluation\n","        for batch_idx, batch in enumerate(tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\")):\n","            context_indices = batch['context_indices'].to(DEVICE)\n","            question_indices = batch['question_indices'].to(DEVICE)\n","            start_labels = batch['start_token_idx'].to(DEVICE)\n","            end_labels = batch['end_token_idx'].to(DEVICE)\n","\n","            start_logits, end_logits = model(context_indices, question_indices)\n","\n","            # Calculate loss\n","            start_loss = criterion(start_logits, start_labels)\n","            end_loss = criterion(end_logits, end_labels)\n","            loss = start_loss + end_loss\n","            total_val_loss += loss.item()\n","\n","            # Calculate simple accuracy for start/end token predictions\n","            # Get the predicted start/end token index by finding the argmax of logits\n","            predicted_start = torch.argmax(start_logits, dim=1)\n","            predicted_end = torch.argmax(end_logits, dim=1)\n","\n","            correct_start_predictions += (predicted_start == start_labels).sum().item()\n","            correct_end_predictions += (predicted_end == end_labels).sum().item()\n","            total_predictions += start_labels.size(0)\n","\n","    avg_val_loss = total_val_loss / len(val_loader)\n","    start_accuracy = correct_start_predictions / total_predictions\n","    end_accuracy = correct_end_predictions / total_predictions\n","\n","    print(f\"Epoch {epoch+1} | Val Loss: {avg_val_loss:.4f} | \"\n","          f\"Start Token Accuracy: {start_accuracy:.4f} | \"\n","          f\"End Token Accuracy: {end_accuracy:.4f}\")\n","\n","print(\"\\n--- Training Complete ---\")\n","\n","# --- Example Usage (Inference) ---\n","print(\"\\n--- Example Inference ---\")\n","\n","# Pick an example from the validation set\n","inference_example = squad_dataset['validation'][10] # Using a different example\n","original_context = inference_example['context']\n","original_question = inference_example['question']\n","original_answer_text = inference_example['answers']['text'][0]\n","\n","print(f\"Original Context: {original_context}\")\n","print(f\"Original Question: {original_question}\")\n","print(f\"Original Answer: {original_answer_text}\")\n","\n","# Preprocess for inference\n","context_tokens_inf = simple_tokenize(original_context)\n","question_tokens_inf = simple_tokenize(original_question)\n","\n","context_indices_inf = tokens_to_indices(context_tokens_inf, word_to_idx, MAX_CONTEXT_LEN, unk_idx=1, pad_idx=0)\n","question_indices_inf = tokens_to_indices(question_tokens_inf, word_to_idx, MAX_QUESTION_LEN, unk_idx=1, pad_idx=0)\n","\n","# Convert to tensors and add batch dimension\n","context_tensor_inf = torch.tensor(context_indices_inf, dtype=torch.long).unsqueeze(0).to(DEVICE)\n","question_tensor_inf = torch.tensor(question_indices_inf, dtype=torch.long).unsqueeze(0).to(DEVICE)\n","\n","model.eval() # Set model to evaluation mode\n","with torch.no_grad():\n","    start_logits_inf, end_logits_inf = model(context_tensor_inf, question_tensor_inf)\n","\n","# Get predicted start and end indices\n","predicted_start_idx = torch.argmax(start_logits_inf, dim=1).item()\n","predicted_end_idx = torch.argmax(end_logits_inf, dim=1).item()\n","\n","# Ensure predicted_start_idx <= predicted_end_idx\n","if predicted_start_idx > predicted_end_idx:\n","    predicted_start_idx, predicted_end_idx = predicted_end_idx, predicted_start_idx\n","\n","print(f\"Predicted Start Token Index: {predicted_start_idx}\")\n","print(f\"Predicted End Token Index: {predicted_end_idx}\")\n","\n","# Reconstruct the answer from tokens\n","predicted_answer_tokens = context_tokens_inf[predicted_start_idx : predicted_end_idx + 1]\n","predicted_answer = \" \".join(predicted_answer_tokens)\n","\n","print(f\"Predicted Answer: {predicted_answer}\")\n","print(f\"Actual Answer: {original_answer_text}\")\n","\n","# Note on evaluation metrics:\n","# For a full SQuAD evaluation, one would typically calculate Exact Match (EM) and F1 score.\n","# This requires more sophisticated post-processing of predictions (e.g., handling cases\n","# where predicted start > predicted end, or ensuring the predicted span is valid).\n","# For this simple example, we focused on token-level accuracy and loss.\n"],"metadata":{"id":"DNwsf3yVE5-K"},"execution_count":null,"outputs":[]}]}